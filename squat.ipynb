{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ultralytics\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics.utils.downloads import download\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import mediapipe as mp\n",
    "# import numpy as np\n",
    "# import time\n",
    "\n",
    "# # Initialize MediaPipe Pose\n",
    "# mp_pose = mp.solutions.pose\n",
    "# pose = mp_pose.Pose()\n",
    "\n",
    "# # Threshold values\n",
    "# STATE_THRESH = 90  # Knee angle threshold to determine squat state\n",
    "# OFFSET_THRESH = 15  # Offset angle threshold for warning\n",
    "# FEEDBACK_THRESH = 10  # Angle deviation threshold for feedback\n",
    "# INACTIVE_THRESH = 3  # Seconds of inactivity before reset\n",
    "\n",
    "# # Initialize state variables\n",
    "# squat_counter_correct = 0\n",
    "# squat_counter_incorrect = 0\n",
    "# prev_state = None\n",
    "# inactive_time = 0\n",
    "# last_activity_time = time.time()\n",
    "\n",
    "# # Function to calculate angle between three points\n",
    "# def calculate_angle(a, b, c):\n",
    "#     a = np.array(a)\n",
    "#     b = np.array(b)\n",
    "#     c = np.array(c)\n",
    "    \n",
    "#     ba = a - b\n",
    "#     bc = c - b\n",
    "    \n",
    "#     cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
    "#     angle = np.arccos(np.clip(cosine_angle, -1.0, 1.0))\n",
    "    \n",
    "#     return np.degrees(angle)\n",
    "\n",
    "# # Function to check squat correctness\n",
    "# def is_correct_squat(knee_angle, hip_angle, offset_angle):\n",
    "#     if abs(offset_angle) > OFFSET_THRESH:\n",
    "#         return False, \"Incorrect Posture: Maintain Proper Alignment!\"\n",
    "    \n",
    "#     if knee_angle < STATE_THRESH:\n",
    "#         if hip_angle < 60:  # Example heuristic, adjust as needed\n",
    "#             return False, \"Incorrect Squat: Lower your hips properly!\"\n",
    "#         return True, \"Good Squat!\"\n",
    "    \n",
    "#     return None, \"\"  # No squat detected\n",
    "\n",
    "# # Load video\n",
    "# cap = cv2.VideoCapture('squat_video.mp4')\n",
    "\n",
    "# while cap.isOpened():\n",
    "#     ret, frame = cap.read()\n",
    "#     if not ret:\n",
    "#         break\n",
    "    \n",
    "#     # Convert frame to RGB\n",
    "#     rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "#     # Process the frame with MediaPipe Pose\n",
    "#     result = pose.process(rgb_frame)\n",
    "\n",
    "#     if result.pose_landmarks:\n",
    "#         landmarks = result.pose_landmarks.landmark\n",
    "#         h, w, _ = frame.shape\n",
    "\n",
    "#         # Extract keypoints (left side used, you can extend for right)\n",
    "#         shoulder = (int(landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].x * w), \n",
    "#                     int(landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].y * h))\n",
    "#         hip = (int(landmarks[mp_pose.PoseLandmark.LEFT_HIP].x * w), \n",
    "#                int(landmarks[mp_pose.PoseLandmark.LEFT_HIP].y * h))\n",
    "#         knee = (int(landmarks[mp_pose.PoseLandmark.LEFT_KNEE].x * w), \n",
    "#                 int(landmarks[mp_pose.PoseLandmark.LEFT_KNEE].y * h))\n",
    "#         ankle = (int(landmarks[mp_pose.PoseLandmark.LEFT_ANKLE].x * w), \n",
    "#                  int(landmarks[mp_pose.PoseLandmark.LEFT_ANKLE].y * h))\n",
    "\n",
    "#         # Calculate angles\n",
    "#         knee_angle = calculate_angle(hip, knee, ankle)\n",
    "#         hip_angle = calculate_angle(shoulder, hip, knee)\n",
    "#         offset_angle = calculate_angle((knee[0], knee[1]-50), hip, knee)  # Vertical offset\n",
    "\n",
    "#         # Squat correctness check\n",
    "#         squat_state, feedback = is_correct_squat(knee_angle, hip_angle, offset_angle)\n",
    "\n",
    "#         # Count squats based on state changes\n",
    "#         if squat_state is not None:\n",
    "#             if squat_state and (prev_state is None or prev_state is False):\n",
    "#                 squat_counter_correct += 1\n",
    "#             elif not squat_state and (prev_state is None or prev_state is True):\n",
    "#                 squat_counter_incorrect += 1\n",
    "#             prev_state = squat_state\n",
    "#             last_activity_time = time.time()  # Reset inactivity timer\n",
    "\n",
    "#         # Display angles & squat count\n",
    "#         cv2.putText(frame, f'Knee Angle: {int(knee_angle)}', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "#         cv2.putText(frame, f'Hip Angle: {int(hip_angle)}', (50, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "#         cv2.putText(frame, f'Squats Correct: {squat_counter_correct}', (50, 110), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "#         cv2.putText(frame, f'Squats Incorrect: {squat_counter_incorrect}', (50, 140), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "#         cv2.putText(frame, feedback, (50, 180), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)\n",
    "\n",
    "#         # Draw landmarks & lines\n",
    "#         cv2.circle(frame, shoulder, 5, (255, 0, 0), -1)\n",
    "#         cv2.circle(frame, hip, 5, (0, 0, 255), -1)\n",
    "#         cv2.circle(frame, knee, 5, (0, 255, 0), -1)\n",
    "#         cv2.circle(frame, ankle, 5, (255, 0, 0), -1)\n",
    "#         cv2.line(frame, shoulder, hip, (255, 255, 0), 2)\n",
    "#         cv2.line(frame, hip, knee, (0, 255, 255), 2)\n",
    "#         cv2.line(frame, knee, ankle, (255, 0, 255), 2)\n",
    "\n",
    "#     # Compute inactivity time\n",
    "#     inactive_time = time.time() - last_activity_time\n",
    "#     if inactive_time > INACTIVE_THRESH:\n",
    "#         squat_counter_correct, squat_counter_incorrect = 0, 0  # Reset counters\n",
    "#         prev_state = None\n",
    "\n",
    "#     # Show video\n",
    "#     cv2.imshow('Squat Detection', frame)\n",
    "\n",
    "#     if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# MediaPipe Setup\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Function to calculate angle\n",
    "def calculate_angle(a, b, c):\n",
    "    a = np.array(a)  # First point\n",
    "    b = np.array(b)  # Midpoint\n",
    "    c = np.array(c)  # End point\n",
    "    \n",
    "    ba = a - b\n",
    "    bc = c - b\n",
    "\n",
    "    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
    "    angle = np.arccos(np.clip(cosine_angle, -1.0, 1.0))\n",
    "\n",
    "    return np.degrees(angle)\n",
    "\n",
    "# Placeholder function to check if squat is correct using GNN\n",
    "def check_correct_squat(joint_features):\n",
    "    \"\"\"\n",
    "    Replace this function with a trained GNN model for classification.\n",
    "    joint_features: List of angles and distances forming a feature vector.\n",
    "    Returns: 'correct' or 'incorrect' squat.\n",
    "    \"\"\"\n",
    "    return \"correct\"  # Placeholder output, replace with GNN inference\n",
    "\n",
    "# OpenCV Video Capture\n",
    "cap = cv2.VideoCapture(\"squat_video.mp4\")  # Change to 0 for webcam\n",
    "\n",
    "# Squat Counter Variables\n",
    "counter = 0\n",
    "stage = None\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert image to RGB\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    result = pose.process(image)\n",
    "\n",
    "    # Convert back to BGR\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    if result.pose_landmarks:\n",
    "        # Extract key landmarks\n",
    "        landmarks = result.pose_landmarks.landmark\n",
    "        hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP].x, landmarks[mp_pose.PoseLandmark.LEFT_HIP].y]\n",
    "        knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE].x, landmarks[mp_pose.PoseLandmark.LEFT_KNEE].y]\n",
    "        ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE].x, landmarks[mp_pose.PoseLandmark.LEFT_ANKLE].y]\n",
    "        shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].y]\n",
    "\n",
    "        # Calculate angles\n",
    "        knee_angle = calculate_angle(hip, knee, ankle)\n",
    "        hip_angle = calculate_angle(shoulder, hip, knee)\n",
    "\n",
    "        # Display angles\n",
    "        cv2.putText(image, f'Knee Angle: {int(knee_angle)}', (50, 50),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "        cv2.putText(image, f'Hip Angle: {int(hip_angle)}', (50, 80),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "        # Squat detection logic\n",
    "        if knee_angle < 90:  # Going down\n",
    "            stage = \"down\"\n",
    "        if knee_angle > 160 and stage == \"down\":  # Standing up\n",
    "            stage = \"up\"\n",
    "            counter += 1\n",
    "\n",
    "        # GNN-based squat evaluation\n",
    "        squat_status = check_correct_squat([hip_angle, knee_angle])\n",
    "\n",
    "        # Display squat count and correctness\n",
    "        cv2.putText(image, f'Count: {counter}', (50, 110),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "        cv2.putText(image, f'Squat: {squat_status}', (50, 140),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 2)\n",
    "\n",
    "        # Draw landmarks\n",
    "        mp_drawing.draw_landmarks(image, result.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "    # Show output\n",
    "    cv2.imshow(\"Squat Detection\", image)\n",
    "\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import mediapipe as mp\n",
    "# import numpy as np\n",
    "# import math\n",
    "\n",
    "# # Initialize MediaPipe Pose model\n",
    "# mp_pose = mp.solutions.pose\n",
    "# pose = mp_pose.Pose()\n",
    "\n",
    "# # Function to calculate angle between three points\n",
    "# def calculate_angle(a, b, c):\n",
    "#     \"\"\"Calculate angle between three points (in degrees).\"\"\"\n",
    "#     a = np.array(a)  \n",
    "#     b = np.array(b)  \n",
    "#     c = np.array(c)  \n",
    "    \n",
    "#     ba = a - b\n",
    "#     bc = c - b\n",
    "    \n",
    "#     cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
    "#     angle = np.arccos(np.clip(cosine_angle, -1.0, 1.0))\n",
    "    \n",
    "#     return np.degrees(angle)\n",
    "\n",
    "# # Function to check if camera is sideways\n",
    "# def is_camera_sideways(landmarks):\n",
    "#     \"\"\"Check if the shoulders are horizontally aligned (side view).\"\"\"\n",
    "#     left_shoulder = landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value]\n",
    "#     right_shoulder = landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value]\n",
    "\n",
    "#     shoulder_distance_x = abs(left_shoulder.x - right_shoulder.x)\n",
    "#     shoulder_distance_y = abs(left_shoulder.y - right_shoulder.y)\n",
    "\n",
    "#     return shoulder_distance_x > shoulder_distance_y  # Side-view condition\n",
    "\n",
    "# # Function to determine squat correctness & feedback\n",
    "# def get_feedback(hip_angle, knee_angle, ankle_angle, correct_ranges):\n",
    "#     \"\"\"\n",
    "#     Provide feedback based on the largest deviation from the correct squat angles.\n",
    "#     \"\"\"\n",
    "#     ideal_hip_range = correct_ranges[\"hip\"]\n",
    "#     ideal_knee_range = correct_ranges[\"knee\"]\n",
    "#     ideal_ankle_range = correct_ranges[\"ankle\"]\n",
    "\n",
    "#     # Compute errors\n",
    "#     hip_error = min(abs(hip_angle - ideal_hip_range[0]), abs(hip_angle - ideal_hip_range[1]))\n",
    "#     knee_error = min(abs(knee_angle - ideal_knee_range[0]), abs(knee_angle - ideal_knee_range[1]))\n",
    "#     # ankle_error = min(abs(ankle_angle - ideal_ankle_range[0]), abs(ankle_angle - ideal_ankle_range[1]))\n",
    "\n",
    "#     # Find max error and give feedback\n",
    "#     # max_error = max(hip_error, knee_error, ankle_error)\n",
    "#     max_error = max(hip_error, knee_error)\n",
    "#     if max_error == hip_error:\n",
    "#         if hip_angle > ideal_hip_range[1]:\n",
    "#             output.append(2)\n",
    "#             return \"Lower your hips\" \n",
    "#         else:\n",
    "#             output.append(3)\n",
    "#             return \"Raise your hips slightly\"\n",
    "        \n",
    "#     elif max_error == knee_error:\n",
    "#         if knee_angle > ideal_knee_range[1]:\n",
    "#             output.append(4)\n",
    "#             return \"Bend your knees more\"  \n",
    "#         else:\n",
    "#             output.append(5)\n",
    "#             return\"Straighten your knees slightly\"\n",
    "#     # elif max_error == ankle_error:\n",
    "#     #     return \"Adjust your ankle position\"\n",
    "\n",
    "#     return \"Good squat!\"\n",
    "# def get_normalized_coords(landmark):\n",
    "#                 return [landmark.x - mid_hip[0], landmark.y - mid_hip[1]]\n",
    "# # Squat detection parameters\n",
    "# correct_ranges = {\n",
    "#     \"hip\": (60, 90),  # Ideal hip angle range\n",
    "#     \"knee\": (70, 100),  # Ideal knee angle range\n",
    "#     \"ankle\": (80, 110)  # Ideal ankle angle range\n",
    "# }\n",
    "# HIP_SQUAT_THRESHOLD = 160     # Hip angle threshold to detect squatting\n",
    "# HIP_STANDING_THRESHOLD = 160  # Hip angle threshold to detect standing\n",
    "# HIP_SQUAT_DETECTION_RANGE = (40, 160)  # Larger range for detecting squats\n",
    "\n",
    "# # Video capture\n",
    "# cap = cv2.VideoCapture(\"squat05.mp4\")  # Change to 0 for webcam\n",
    "\n",
    "# squat_count = 0\n",
    "# squat_active = False\n",
    "# output= []\n",
    "# data_list = []\n",
    "# while cap.isOpened():\n",
    "#     ret, frame = cap.read()\n",
    "#     if not ret:\n",
    "#         break\n",
    "\n",
    "#     # Convert to RGB for MediaPipe\n",
    "#     image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "#     results = pose.process(image)\n",
    "\n",
    "#     # Convert back to BGR for OpenCV\n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "#     if results.pose_landmarks:\n",
    "#         landmarks = results.pose_landmarks.landmark\n",
    "#         mid_hip = np.array([(landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x +\n",
    "#                                  landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x) / 2,\n",
    "#                                 (landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y +\n",
    "#                                  landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y) / 2])\n",
    "#         left_hip = get_normalized_coords(landmarks[mp_pose.PoseLandmark.LEFT_HIP.value])\n",
    "#         right_hip = get_normalized_coords(landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value])\n",
    "#         left_knee = get_normalized_coords(landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value])\n",
    "#         right_knee = get_normalized_coords(landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value])\n",
    "#         left_ankle = get_normalized_coords(landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value])\n",
    "#         right_ankle = get_normalized_coords(landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value])\n",
    "\n",
    "#         norm_shoulder = get_normalized_coords(landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value])\n",
    "\n",
    "#         if not is_camera_sideways(landmarks):\n",
    "#             cv2.putText(image, \"Face the camera sideways!\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "#             cv2.imshow(\"Squat Detection\", image)\n",
    "#             output.append(0)\n",
    "#             continue  # Skip this frame if camera is not sideways\n",
    "            \n",
    "#         # Get required landmarks\n",
    "#         hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,\n",
    "#                landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "#         knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x,\n",
    "#                 landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "#         ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,\n",
    "#                  landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "#         shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "#                     landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "        \n",
    "#         # Compute angles\n",
    "#         hip_angle = calculate_angle(shoulder, hip, knee)\n",
    "#         knee_angle = calculate_angle(hip, knee, ankle)\n",
    "#         ankle_angle = calculate_angle(knee, ankle, [ankle[0], ankle[1] + 0.1])  # Vertical ref.\n",
    "\n",
    "#         # Check for squat within defined hip angle range\n",
    "#         if HIP_SQUAT_DETECTION_RANGE[0] <= hip_angle <= HIP_SQUAT_DETECTION_RANGE[1]:\n",
    "#             if hip_angle < HIP_SQUAT_THRESHOLD and not squat_active:\n",
    "#                 squat_active = True\n",
    "\n",
    "#             if hip_angle > HIP_STANDING_THRESHOLD and squat_active:\n",
    "#                 squat_active = False\n",
    "#                 squat_count += 1  # Increment squat counter\n",
    "\n",
    "#             # Get feedback **only if inside hip angle range**\n",
    "#             feedback_text = get_feedback(hip_angle, knee_angle, ankle_angle, correct_ranges)\n",
    "#         else:\n",
    "#             feedback_text = \"No squat detected\"\n",
    "#             output.append(1) \n",
    "#         # Display angles\n",
    "#         cv2.putText(image, f\"Hip Angle: {int(hip_angle)}\", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "#         cv2.putText(image, f\"Knee Angle: {int(knee_angle)}\", (50, 130), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "#         cv2.putText(image, f\"Ankle Angle: {int(ankle_angle)}\", (50, 160), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "#         cv2.putText(image, f\"Squat Count: {squat_count}\", (50, 190), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)\n",
    "\n",
    "#         # Display feedback\n",
    "#         cv2.putText(image, feedback_text, (50, 220), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "#         data_list.append([\n",
    "#                 left_hip[0], left_hip[1], right_hip[0], right_hip[1],\n",
    "#                 left_knee[0], left_knee[1], right_knee[0], right_knee[1],\n",
    "#                 left_ankle[0], left_ankle[1], right_ankle[0], right_ankle[1],output[-1]\n",
    "#             ]) \n",
    "        \n",
    "#     # Show frame\n",
    "#     cv2.imshow(\"Squat Detection\", image)\n",
    "\n",
    "#     if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved to 'squat_data.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data_list, columns=[\n",
    "    \"left_hip_x\", \"left_hip_y\", \"right_hip_x\", \"right_hip_y\",\n",
    "    \"left_knee_x\", \"left_knee_y\", \"right_knee_x\", \"right_knee_y\",\n",
    "    \"left_ankle_x\", \"left_ankle_y\", \"right_ankle_x\", \"right_ankle_y\",\n",
    "    \"label\"\n",
    "])\n",
    "df.to_csv(\"squat_data.csv\", index=False)\n",
    "\n",
    "print(\"Dataset saved to 'squat_data.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader  \n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import  Dataset\n",
    "import pandas as pd\n",
    "\n",
    "class SquatDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None, pre_transform=None):\n",
    "        super().__init__(None, transform, pre_transform)\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        \n",
    "    def len(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def get(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        # Extract node features (6 points, each with x, y)\n",
    "        x = torch.tensor(row[:-1].values.reshape(6, 2), dtype=torch.float)\n",
    "\n",
    "        # Define edges (fully connected graph for now)\n",
    "        edges = [\n",
    "            (0, 1), (0, 2), (2,4), (1, 3),(3,5)\n",
    "        ]\n",
    "        edges += [(j, i) for i, j in edges]\n",
    "\n",
    "        # Convert to tensor\n",
    "        edge_index = torch.tensor(edges, dtype=torch.long).t()\n",
    "\n",
    "        # Label\n",
    "        y = torch.tensor([row.iloc[-1]], dtype=torch.long)  # Use .iloc to get last item by position\n",
    "\n",
    "        return Data(x=x, edge_index=edge_index, y=y)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = SquatDataset(\"squat_dataset.csv\")\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# Define dataset split (e.g., 80% train, 20% validation)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Define DataLoaders for PyTorch Geometric\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "# Define the GNN model\n",
    "\n",
    "class SquatGNN(torch.nn.Module):\n",
    "    def __init__(self, input_dim=2, hidden_dim=32, output_dim=6):\n",
    "        super(SquatGNN, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, 2*hidden_dim)\n",
    "        self.conv2 = GCNConv(2*hidden_dim, hidden_dim)\n",
    "        self.conv3 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)  \n",
    "        self.dropout= nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        # x = torch.reshape(x,(-1,6,2)).to(device)\n",
    "        # edge_index = torch.reshape(edge_index,(2,10,-1)).to(device)\n",
    "        \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.leaky_relu(x, negative_slope=0.01)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.leaky_relu(x, negative_slope=0.01)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = global_mean_pool(x, data.batch)  # Global mean pooling\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "        return (F.log_softmax(x))  # Use log-softmax for NLLLoss\n",
    "        return [x,edge_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SquatGNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 98.2563\n",
      "Epoch 2, Loss: 36.3274\n",
      "Epoch 3, Loss: 30.8957\n",
      "Epoch 4, Loss: 25.3495\n",
      "Epoch 5, Loss: 25.5369\n",
      "Epoch 6, Loss: 19.7651\n",
      "Epoch 7, Loss: 25.9138\n",
      "Epoch 8, Loss: 21.4535\n",
      "Epoch 9, Loss: 29.7243\n",
      "Epoch 10, Loss: 19.3776\n",
      "Epoch 11, Loss: 19.7951\n",
      "Epoch 12, Loss: 23.4760\n",
      "Epoch 13, Loss: 23.4900\n",
      "Epoch 14, Loss: 17.8586\n",
      "Epoch 15, Loss: 19.3943\n",
      "Epoch 16, Loss: 23.1708\n",
      "Epoch 17, Loss: 16.8538\n",
      "Epoch 18, Loss: 17.5717\n",
      "Epoch 19, Loss: 18.7093\n",
      "Epoch 20, Loss: 18.1225\n",
      "Epoch 21, Loss: 21.3452\n",
      "Epoch 22, Loss: 19.7122\n",
      "Epoch 23, Loss: 18.5236\n",
      "Epoch 24, Loss: 24.6279\n",
      "Epoch 25, Loss: 17.1394\n",
      "Epoch 26, Loss: 22.1856\n",
      "Epoch 27, Loss: 17.9609\n",
      "Epoch 28, Loss: 22.2531\n",
      "Epoch 29, Loss: 17.3014\n",
      "Epoch 30, Loss: 17.2984\n",
      "Epoch 31, Loss: 16.2882\n",
      "Epoch 32, Loss: 19.5512\n",
      "Epoch 33, Loss: 17.7541\n",
      "Epoch 34, Loss: 15.5685\n",
      "Epoch 35, Loss: 21.4511\n",
      "Epoch 36, Loss: 17.1107\n",
      "Epoch 37, Loss: 14.6793\n",
      "Epoch 38, Loss: 18.1255\n",
      "Epoch 39, Loss: 19.0194\n",
      "Epoch 40, Loss: 17.1817\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "# loss_fn = nn.NLLLoss()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "epochs = 40\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data) \n",
    "        #break\n",
    "        loss = loss_fn(out, data.y)  \n",
    "        #break\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.14563106796116\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def evaluate(model, val_loader, device):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():  # No gradient updates during validation\n",
    "        for data in val_loader:\n",
    "            data = data.to(device)\n",
    "            output = model(data)  # Forward pass\n",
    "            preds = output.argmax(dim=1)  # Get predicted class\n",
    "            correct += (preds == data.y).sum().item()\n",
    "            total += data.y.size(0)\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "print(evaluate(model,val_loader,device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"squat_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  -0.022024,  -0.0066378,    0.022024,   0.0066378,   -0.034584,     0.15786,    0.036604,     0.16804,   -0.081443,     0.31659,     0.03867,     0.34752])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.columns[:-1]].iloc[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SLAM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
